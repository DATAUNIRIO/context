<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="Poverty and Inequality with Complex Survey Data" />
<meta property="og:type" content="book" />


<meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
<meta name="github-repo" content="gilhermejacob/context" />

<meta name="author" content="Guilherme Jacob, Anthony Damico, and Djalma Pessoa" />

<meta name="date" content="2016-12-14" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">

<title>Poverty and Inequality with Complex Survey Data</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="index.html#introduction"><span class="toc-section-number">1</span> Introduction</a><ul>
<li><a href="1-1-install.html#install"><span class="toc-section-number">1.1</span> Installation</a></li>
<li><a href="1-2-survey.html#survey"><span class="toc-section-number">1.2</span> Complex surveys and statistical inference</a></li>
<li><a href="1-3-linearization.html#linearization"><span class="toc-section-number">1.3</span> Linearization</a></li>
<li><a href="1-4-influence-function.html#influence-function"><span class="toc-section-number">1.4</span> Influence function</a></li>
<li><a href="1-5-the-variance-estimator.html#the-variance-estimator"><span class="toc-section-number">1.5</span> The variance estimator</a></li>
<li><a href="1-6-influence-functions-examples.html#influence-functions---examples"><span class="toc-section-number">1.6</span> Influence functions - Examples</a></li>
<li><a href="1-7-linearization-by-influence-function-examples.html#linearization-by-influence-function---examples"><span class="toc-section-number">1.7</span> Linearization by influence function - Examples</a></li>
<li class="has-sub"><a href="1-8-structure-of-the-library.html#structure-of-the-library"><span class="toc-section-number">1.8</span> Structure of the library</a><ul>
<li><a href="1-8-structure-of-the-library.html#examples-of-use-of-the-library-convey"><span class="toc-section-number">1.8.1</span> Examples of use of the library convey</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="2-poverty.html#poverty"><span class="toc-section-number">2</span> Poverty Indices</a><ul>
<li><a href="2-1-the-gender-pay-gap-svygpg.html#the-gender-pay-gap-svygpg"><span class="toc-section-number">2.1</span> The Gender Pay Gap (svygpg)</a></li>
<li><a href="2-2-quintile-share-ratio-svyqsr.html#quintile-share-ratio-svyqsr"><span class="toc-section-number">2.2</span> Quintile Share Ratio (svyqsr)</a></li>
<li><a href="2-3-relative-median-income-ratio-svyrmir.html#relative-median-income-ratio-svyrmir"><span class="toc-section-number">2.3</span> Relative Median Income Ratio (svyrmir)</a></li>
<li><a href="2-4-relative-median-poverty-gap-svyrmpg.html#relative-median-poverty-gap-svyrmpg"><span class="toc-section-number">2.4</span> Relative Median Poverty Gap (svyrmpg)</a></li>
<li><a href="2-5-median-income-below-the-at-risk-of-poverty-threshold-svypoormed.html#median-income-below-the-at-risk-of-poverty-threshold-svypoormed"><span class="toc-section-number">2.5</span> Median Income Below the At Risk of Poverty Threshold (svypoormed)</a></li>
<li><a href="2-6-foster-greer-thorbecke-class-svyfgt.html#foster-greer-thorbecke-class-svyfgt"><span class="toc-section-number">2.6</span> Foster-Greer-Thorbecke class (svyfgt)</a></li>
</ul></li>
<li class="has-sub"><a href="3-inequality.html#inequality"><span class="toc-section-number">3</span> Inequality Measurement</a><ul>
<li><a href="3-1-lorenz-curve-svylorenz.html#lorenz-curve-svylorenz"><span class="toc-section-number">3.1</span> Lorenz Curve (svylorenz)</a></li>
<li class="has-sub"><a href="3-2-measures-derived-from-the-lorenz-curve.html#measures-derived-from-the-lorenz-curve"><span class="toc-section-number">3.2</span> Measures derived from the Lorenz Curve</a><ul>
<li><a href="3-2-measures-derived-from-the-lorenz-curve.html#gini-index-svygini"><span class="toc-section-number">3.2.1</span> Gini index (svygini)</a></li>
<li><a href="3-2-measures-derived-from-the-lorenz-curve.html#amato-index-svyamato"><span class="toc-section-number">3.2.2</span> Amato index (svyamato)</a></li>
<li><a href="3-2-measures-derived-from-the-lorenz-curve.html#zenga-index-and-curve-svyzenga-svyzengacurve"><span class="toc-section-number">3.2.3</span> Zenga Index and Curve (svyzenga, svyzengacurve)</a></li>
</ul></li>
<li class="has-sub"><a href="3-3-entropy-based-measures.html#entropy-based-measures"><span class="toc-section-number">3.3</span> Entropy-based Measures</a><ul>
<li><a href="3-3-entropy-based-measures.html#generalized-entropy-and-decomposition-svygei-svygeidec"><span class="toc-section-number">3.3.1</span> Generalized Entropy and Decomposition (svygei, svygeidec)</a></li>
<li><a href="3-3-entropy-based-measures.html#renyi-divergence-svyrenyi"><span class="toc-section-number">3.3.2</span> Rényi Divergence (svyrenyi)</a></li>
<li><a href="3-3-entropy-based-measures.html#j-divergence-and-decomposition-svyjdiv-svyjdivdec"><span class="toc-section-number">3.3.3</span> J-Divergence and Decomposition (svyjdiv, svyjdivdec)</a></li>
<li><a href="3-3-entropy-based-measures.html#atkinson-index-svyatk"><span class="toc-section-number">3.3.4</span> Atkinson index (svyatk)</a></li>
</ul></li>
<li class="has-sub"><a href="3-4-examples.html#examples"><span class="toc-section-number">3.4</span> Examples</a><ul>
<li><a href="3-4-examples.html#replicating-barabesi-et-al.-2016"><span class="toc-section-number">3.4.1</span> Replicating Barabesi et al. (2016)</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="4-multidimensional.html#multidimensional"><span class="toc-section-number">4</span> Multidimensional Indices</a><ul>
<li><a href="4-1-alkire-foster-class-and-decomposition-svyafc-svyafcdec.html#alkire-foster-class-and-decomposition-svyafc-svyafcdec"><span class="toc-section-number">4.1</span> Alkire-Foster Class and Decomposition (svyafc, svyafcdec)</a></li>
<li><a href="4-2-bourguignon-1999-inequality-class-svybmi.html#bourguignon-1999-inequality-class-svybmi"><span class="toc-section-number">4.2</span> Bourguignon (1999) inequality class (svybmi)</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="entropy-based-measures" class="section level2">
<h2><span class="header-section-number">3.3</span> Entropy-based Measures</h2>
<p>Entropy is a concept derived from information theory, meaning the expected amount of information given the occurrence of an event. Following <span class="citation">(Shannon <label for="tufte-mn-32" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-32" class="margin-toggle">1948<span class="marginnote">Shannon, Claude E. 1948. “A Mathematical Theory of Communication.” <em>Bell System Technical Journal</em> 27 (3). Blackwell Publishing Ltd: 379–423. doi:<a href="https://doi.org/10.1002/j.1538-7305.1948.tb01338.x">10.1002/j.1538-7305.1948.tb01338.x</a>.</span>)</span>, given an event <span class="math inline">\(y\)</span> with probability density function <span class="math inline">\(f(\cdot)\)</span>, the information content given the occurrence of <span class="math inline">\(y\)</span> can be defined as <span class="math inline">\(g(f(y)) \colon= - \log f(y)\)</span>. Therefore, the expected information or, put simply, the <em>entropy</em> is</p>
<p><span class="math display">\[
H(f) \colon = -E \big[ \log f(y) \big] = - \int_{-\infty}^{\infty} f(y) \log f(y) dy
\]</span></p>
<p>Assuming a discrete distribution, with <span class="math inline">\(p_k\)</span> as the probability of occurring event <span class="math inline">\(k \in K\)</span>, the entropy formula takes the form:</p>
<p><span class="math display">\[
H = - \sum_{k \in K} p_k \log p_k \text{.}
\]</span></p>
<p>The main idea behind it is that the expected amount of information of an event is inversely proportional to the probability of its occurrence. In other words, the information derived from the observation of a rare event is higher than of the information of more probable events.</p>
<p>Using the intuition presented in <span class="citation">(Cowell, Flachaire, and Bandyopadhyay <label for="tufte-mn-33" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-33" class="margin-toggle">2009<span class="marginnote">Cowell, Frank A., Emmanuel Flachaire, and Sanghamitra Bandyopadhyay. 2009. “Goodness-of-Fit: An Economic Approach.” Economics Series Working Papers 444. University of Oxford, Department of Economics. <a href="https://ideas.repec.org/p/oxf/wpaper/444.html" class="uri">https://ideas.repec.org/p/oxf/wpaper/444.html</a>.</span>)</span>, substituting the density function by the income share of an individual <span class="math inline">\(s(q) = {F}^{-1}(q) / \int_{0}^{1} F^{-1}(t)dt = y/\mu\)</span>, the entropy function becomes the Theil inequality index</p>
<p><span class="math display">\[
I_{Theil} = \int_{0}^{\infty} \frac{y}{\mu} \log \bigg( \frac{y}{\mu} \bigg) dF(y) = -H(s)
\]</span></p>
<p>Therefore, the entropy-based inequality measure increases as a person’s income <span class="math inline">\(y\)</span> deviates from the mean <span class="math inline">\(\mu\)</span>. This is the basic idea behind entropy-based inequality measures.</p>
<div id="generalized-entropy-and-decomposition-svygei-svygeidec" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Generalized Entropy and Decomposition (svygei, svygeidec)</h3>
<p>Using a generalization of the information function, now defined as <span class="math inline">\(g(f) = \frac{1}{\alpha-1} [ 1 - f^{\alpha - 1} ]\)</span>, the <span class="math inline">\(\alpha\)</span>-class entropy is <span class="math display">\[
H_\alpha(f) = \frac{1}{\alpha - 1} \bigg[ 1 - \int_{-\infty}^{\infty} f(y)^{ \alpha - 1} f(y) dy \bigg] \text{.}
\]</span></p>
<p>This relates to a class of inequality measures, the Generalized entropy indices, defined as:</p>
<p><span class="math display">\[
GE_\alpha = \frac{1}{\alpha^2 - \alpha} \int_{0}^\infty \bigg[ \bigg( \frac{y}{\mu} \bigg)^\alpha - 1 \bigg]dF(x) = - \frac{-H_\alpha(s) }{ \alpha } \text{.}
\]</span></p>
<p>The parameter <span class="math inline">\(\alpha\)</span> also has an economic interpretation: as <span class="math inline">\(\alpha\)</span> increases, the influence of top incomes upon the index increases. In some cases, this measure takes special forms, such as mean log deviation and the aforementioned Theil index.</p>
<p>In order to estimate it, <span class="citation">(Biewen and Jenkins <label for="tufte-mn-34" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-34" class="margin-toggle">2003<span class="marginnote">Biewen, Martin, and Stephen Jenkins. 2003. “Estimation of Generalized Entropy and Atkinson Inequality Indices from Complex Survey Data.” Discussion Papers of DIW Berlin 345. DIW Berlin, German Institute for Economic Research. <a href="http://EconPapers.repec.org/RePEc:diw:diwwpp:dp345" class="uri">http://EconPapers.repec.org/RePEc:diw:diwwpp:dp345</a>.</span>)</span> proposed the following:</p>
<p><span class="math display">\[
GE_\alpha =
\begin{cases}
( \alpha^2 - \alpha)^{-1} \big[ U_0^{\alpha - 1} U_1^{-\alpha} U_\alpha -1 \big], &amp; \text{if } \alpha \in \mathbb{R} \setminus \{0,1\} \\
- T_0 U_0^{-1} + \log ( U_1 / U_0 ), &amp;\text{if } \alpha \rightarrow 0 \\
- T_1 U_1^{-1} - \log ( U_1 / U_0 ), &amp; \text{if } \alpha \rightarrow 1
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(U_\gamma = \sum_{i \in S} w_i \cdot y_i^\gamma\)</span> and <span class="math inline">\(T_\gamma = \sum_{i \in S} w_i \cdot y_i^\gamma \cdot \log y_i\)</span>. since those are all functions of totals, the linearization of the indices are easily achieved using the theorems described in <span class="citation">(Deville <label for="tufte-mn-35" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-35" class="margin-toggle">1999<span class="marginnote">Deville, Jean-Claude. 1999. “Variance Estimation for Complex Statistics and Estimators: Linearization and Residual Techniques.” <em>Survey Methodology</em> 25 (2): 193–203. <a href="http://www.statcan.gc.ca/pub/12-001-x/1999002/article/4882-eng.pdf" class="uri">http://www.statcan.gc.ca/pub/12-001-x/1999002/article/4882-eng.pdf</a>.</span>)</span>.</p>
<p>This class also has several desirable properties, such as additive decomposition. The additive decomposition allows to compare the effects of inequality within and between population groups on the population inequality. Put simply, an additive decomposable index allows for:</p>
<p><span class="math display">\[
I_{Total} = I_{Between} + I_{Within} \text{.}
\]</span></p>
</div>
<div id="renyi-divergence-svyrenyi" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Rényi Divergence (svyrenyi)</h3>
<p>Another measure used in areas like ecology, statistics and information theory is Rényi divergence measure. Using the formula defined in <span class="citation">(Langel <label for="tufte-mn-36" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-36" class="margin-toggle">2012<span class="marginnote">Langel, Matti. 2012. “Measuring Inequality in Finite Population Sampling.” PhD thesis. <a href="http://doc.rero.ch/record/29204" class="uri">http://doc.rero.ch/record/29204</a>.</span>)</span>, the estimator can be defined as:</p>
<p><span class="math display">\[
\widehat{R}_\alpha =
\begin{cases}
\frac{1}{\alpha - 1} \log \bigg[ \widehat{N}^{\alpha - 1} \sum_{i \in S} w_i \cdot \bigg( \frac{y_k}{ \widehat{Y} } \bigg) \bigg], &amp;\text{if } \alpha \neq 1, \\
\sum_{i \in S} \frac{w_i y_i}{ \widehat{Y}} \log \frac{\widehat{N} y_i}{\widehat{Y}}, &amp;\text{if } \alpha = 1,
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(\alpha\)</span> is a parameter with a similar economic interpretation to that of the <span class="math inline">\(GE_\alpha\)</span> index.</p>
</div>
<div id="j-divergence-and-decomposition-svyjdiv-svyjdivdec" class="section level3">
<h3><span class="header-section-number">3.3.3</span> J-Divergence and Decomposition (svyjdiv, svyjdivdec)</h3>
<p>Proposed by <span class="citation">(Rohde <label for="tufte-mn-37" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-37" class="margin-toggle">2016<span class="marginnote">Rohde, Nicholas. 2016. “J-Divergence Measurements of Economic Inequality.” <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em> 179 (3): 847–70. doi:<a href="https://doi.org/10.1111/rssa.12153">10.1111/rssa.12153</a>.</span>)</span>, the J-divergence measure can be seen as the sum of <span class="math inline">\(GE_0\)</span> and <span class="math inline">\(GE_1\)</span>, satisfying axioms that, individually, those two indices do not. Using <span class="math inline">\(U_\gamma\)</span> and <span class="math inline">\(T_\gamma\)</span> functions defined in , the estimator can be defined as:</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{J} &amp;= \frac{1}{\widehat{N}} \sum_{i \in S} w_i \bigg( \frac{ y_i - \widehat{\mu} }{ \widehat{\mu} } \bigg) \log \bigg( \frac{y_i}{\widehat{\mu}} \bigg) \\
\therefore \widehat{J} &amp;= \frac{\widehat{T}_1}{\widehat{U}_1} - \frac{ \widehat{T}_0 }{ \widehat{U}_0 }
\end{aligned}
\]</span></p>
<p>Since it is a sum of two additive decomposable measures, <span class="math inline">\(J\)</span> itself is decomposable.</p>
</div>
<div id="atkinson-index-svyatk" class="section level3">
<h3><span class="header-section-number">3.3.4</span> Atkinson index (svyatk)</h3>
<p>Although the original formula was proposed in <span class="citation">(Atkinson <label for="tufte-mn-38" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-38" class="margin-toggle">1970<span class="marginnote">Atkinson, Anthony B. 1970. “On the Measurement of Inequality.” <em>Journal of Economic Theory</em> 2 (3): 244–63. <a href="https://ideas.repec.org/a/eee/jetheo/v2y1970i3p244-263.html" class="uri">https://ideas.repec.org/a/eee/jetheo/v2y1970i3p244-263.html</a>.</span>)</span>, the estimator used here comes from <span class="citation">(Biewen and Jenkins <label for="tufte-mn-39" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-39" class="margin-toggle">2003<span class="marginnote">Biewen, Martin, and Stephen Jenkins. 2003. “Estimation of Generalized Entropy and Atkinson Inequality Indices from Complex Survey Data.” Discussion Papers of DIW Berlin 345. DIW Berlin, German Institute for Economic Research. <a href="http://EconPapers.repec.org/RePEc:diw:diwwpp:dp345" class="uri">http://EconPapers.repec.org/RePEc:diw:diwwpp:dp345</a>.</span>)</span>:</p>
<p><span class="math display">\[
\widehat{A}_\epsilon =
\begin{cases}
 1 - \widehat{U}_0^{ - \epsilon/(1 - \epsilon) } \widehat{U}_1^{ -1 } \widehat{U}_{1 - \epsilon}^{ 1/(1 - \epsilon) } , &amp;\text{if } \epsilon \in \mathbb{R}_+ \setminus\{ 1 \} \\
1 - \widehat{U}_0 \widehat{U}_0^{-1} exp( \widehat{T}_0 \widehat{U}_0^{-1} ), &amp;\text{if } \epsilon \rightarrow1
\end{cases}
\]</span></p>
<p>The <span class="math inline">\(\epsilon\)</span> is an inequality aversion parameter: as it approaches infinity, more weight is given to incomes in bottom of the distribution.</p>
</div>
</div>
<p style="text-align: center;">
<a href="3-2-measures-derived-from-the-lorenz-curve.html"><button class="btn btn-default">Previous</button></a>
<a href="3-4-examples.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
